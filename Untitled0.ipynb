{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pr4vrEnbmTKf"
   },
   "source": [
    "安装cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 256568,
     "status": "ok",
     "timestamp": 1593829597352,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "h-bEYAQVmJpe",
    "outputId": "8e815407-614a-4de9-92a3-65843d0cffe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-04 02:23:19--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
      "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
      "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 190 [application/octet-stream]\n",
      "Saving to: ‘cuda-ubuntu1804.pin’\n",
      "\n",
      "\r",
      "cuda-ubuntu1804.pin   0%[                    ]       0  --.-KB/s               \r",
      "cuda-ubuntu1804.pin 100%[===================>]     190  --.-KB/s    in 0s      \n",
      "\n",
      "2020-07-04 02:23:20 (3.36 MB/s) - ‘cuda-ubuntu1804.pin’ saved [190/190]\n",
      "\n",
      "--2020-07-04 02:23:23--  http://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb\n",
      "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
      "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1896270068 (1.8G) [application/x-deb]\n",
      "Saving to: ‘cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb’\n",
      "\n",
      "cuda-repo-ubuntu180 100%[===================>]   1.77G  55.7MB/s    in 10s     \n",
      "\n",
      "2020-07-04 02:23:33 (176 MB/s) - ‘cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb’ saved [1896270068/1896270068]\n",
      "\n",
      "Selecting previously unselected package cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01.\n",
      "(Reading database ... 144379 files and directories currently installed.)\n",
      "Preparing to unpack cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb ...\n",
      "Unpacking cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01 (1.0-1) ...\n",
      "Setting up cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01 (1.0-1) ...\n",
      "OK\n",
      "Get:1 file:/var/cuda-repo-10-2-local-10.2.89-440.33.01  InRelease\n",
      "Ign:1 file:/var/cuda-repo-10-2-local-10.2.89-440.33.01  InRelease\n",
      "Get:2 file:/var/cuda-repo-10-2-local-10.2.89-440.33.01  Release [574 B]\n",
      "Get:2 file:/var/cuda-repo-10-2-local-10.2.89-440.33.01  Release [574 B]\n",
      "Get:3 file:/var/cuda-repo-10-2-local-10.2.89-440.33.01  Release.gpg [833 B]\n",
      "Get:3 file:/var/cuda-repo-10-2-local-10.2.89-440.33.01  Release.gpg [833 B]\n",
      "Get:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
      "Get:5 file:/var/cuda-repo-10-2-local-10.2.89-440.33.01  Packages [23.8 kB]\n",
      "Ign:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Get:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
      "Get:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
      "Get:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [93.7 kB]\n",
      "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Get:13 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Hit:15 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:16 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [40.0 kB]\n",
      "Get:17 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [87.8 kB]\n",
      "Get:20 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,843 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:22 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [866 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [13.6 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,404 kB]\n",
      "Get:25 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [993 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,292 kB]\n",
      "Get:27 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [9,282 B]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [101 kB]\n",
      "Get:29 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [889 kB]\n",
      "Fetched 7,906 kB in 3s (2,436 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  cuda-11-0 cuda-command-line-tools-11-0 cuda-compiler-11-0 cuda-cudart-11-0\n",
      "  cuda-cudart-dev-11-0 cuda-cuobjdump-11-0 cuda-cupti-11-0 cuda-cupti-dev-11-0\n",
      "  cuda-demo-suite-11-0 cuda-documentation-11-0 cuda-driver-dev-11-0\n",
      "  cuda-gdb-11-0 cuda-libraries-11-0 cuda-libraries-dev-11-0 cuda-memcheck-11-0\n",
      "  cuda-nsight-11-0 cuda-nsight-compute-11-0 cuda-nsight-systems-11-0\n",
      "  cuda-nvcc-11-0 cuda-nvdisasm-11-0 cuda-nvml-dev-11-0 cuda-nvprof-11-0\n",
      "  cuda-nvprune-11-0 cuda-nvrtc-11-0 cuda-nvrtc-dev-11-0 cuda-nvtx-11-0\n",
      "  cuda-nvvp-11-0 cuda-runtime-11-0 cuda-samples-11-0 cuda-sanitizer-11-0\n",
      "  cuda-toolkit-11-0 cuda-tools-11-0 cuda-visual-tools-11-0 libcublas-11-0\n",
      "  libcublas-dev-11-0 libcufft-11-0 libcufft-dev-11-0 libcurand-11-0\n",
      "  libcurand-dev-11-0 libcusolver-11-0 libcusolver-dev-11-0 libcusparse-11-0\n",
      "  libcusparse-dev-11-0 libnpp-11-0 libnpp-dev-11-0 libnvjpeg-11-0\n",
      "  libnvjpeg-dev-11-0\n",
      "The following NEW packages will be installed:\n",
      "  cuda cuda-11-0 cuda-command-line-tools-11-0 cuda-compiler-11-0\n",
      "  cuda-cudart-11-0 cuda-cudart-dev-11-0 cuda-cuobjdump-11-0 cuda-cupti-11-0\n",
      "  cuda-cupti-dev-11-0 cuda-demo-suite-11-0 cuda-documentation-11-0\n",
      "  cuda-driver-dev-11-0 cuda-gdb-11-0 cuda-libraries-11-0\n",
      "  cuda-libraries-dev-11-0 cuda-memcheck-11-0 cuda-nsight-11-0\n",
      "  cuda-nsight-compute-11-0 cuda-nsight-systems-11-0 cuda-nvcc-11-0\n",
      "  cuda-nvdisasm-11-0 cuda-nvml-dev-11-0 cuda-nvprof-11-0 cuda-nvprune-11-0\n",
      "  cuda-nvrtc-11-0 cuda-nvrtc-dev-11-0 cuda-nvtx-11-0 cuda-nvvp-11-0\n",
      "  cuda-runtime-11-0 cuda-samples-11-0 cuda-sanitizer-11-0 cuda-toolkit-11-0\n",
      "  cuda-tools-11-0 cuda-visual-tools-11-0 libcublas-11-0 libcublas-dev-11-0\n",
      "  libcufft-11-0 libcufft-dev-11-0 libcurand-11-0 libcurand-dev-11-0\n",
      "  libcusolver-11-0 libcusolver-dev-11-0 libcusparse-11-0 libcusparse-dev-11-0\n",
      "  libnpp-11-0 libnpp-dev-11-0 libnvjpeg-11-0 libnvjpeg-dev-11-0\n",
      "0 upgraded, 48 newly installed, 0 to remove and 43 not upgraded.\n",
      "Need to get 1,506 MB of archives.\n",
      "After this operation, 3,797 MB of additional disk space will be used.\n",
      "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cudart-11-0 11.0.171-1 [129 kB]\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvrtc-11-0 11.0.167-1 [6,513 kB]\n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas-11-0 11.0.0.191-1 [99.9 MB]\n",
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcufft-11-0 10.1.3.191-1 [92.6 MB]\n",
      "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcurand-11-0 10.2.0.191-1 [39.0 MB]\n",
      "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusolver-11-0 10.4.0.191-1 [253 MB]\n",
      "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusparse-11-0 11.0.0.191-1 [62.3 MB]\n",
      "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnpp-11-0 11.0.0.191-1 [56.2 MB]\n",
      "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnvjpeg-11-0 11.0.0.191-1 [1,386 kB]\n",
      "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-libraries-11-0 11.0.1-1 [2,466 B]\n",
      "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-runtime-11-0 11.0.1-1 [2,408 B]\n",
      "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cuobjdump-11-0 11.0.167-1 [102 kB]\n",
      "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-driver-dev-11-0 11.0.171-1 [25.1 kB]\n",
      "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cudart-dev-11-0 11.0.171-1 [1,659 kB]\n",
      "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvcc-11-0 11.0.167-1 [21.0 MB]\n",
      "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvprune-11-0 11.0.167-1 [53.1 kB]\n",
      "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-compiler-11-0 11.0.1-1 [2,400 B]\n",
      "Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvrtc-dev-11-0 11.0.167-1 [21.6 kB]\n",
      "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas-dev-11-0 11.0.0.191-1 [102 MB]\n",
      "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcufft-dev-11-0 10.1.3.191-1 [170 MB]\n",
      "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcurand-dev-11-0 10.2.0.191-1 [39.2 MB]\n",
      "Get:22 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusolver-dev-11-0 10.4.0.191-1 [17.9 MB]\n",
      "Get:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusparse-dev-11-0 11.0.0.191-1 [62.5 MB]\n",
      "Get:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnpp-dev-11-0 11.0.0.191-1 [57.0 MB]\n",
      "Get:25 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnvjpeg-dev-11-0 11.0.0.191-1 [1,318 kB]\n",
      "Get:26 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-libraries-dev-11-0 11.0.1-1 [2,484 B]\n",
      "Get:27 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cupti-11-0 11.0.167-1 [10.3 MB]\n",
      "Get:28 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cupti-dev-11-0 11.0.167-1 [2,282 kB]\n",
      "Get:29 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvdisasm-11-0 11.0.167-1 [28.2 MB]\n",
      "Get:30 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-gdb-11-0 11.0.172-1 [3,829 kB]\n",
      "Get:31 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-memcheck-11-0 11.0.167-1 [144 kB]\n",
      "Get:32 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvprof-11-0 11.0.167-1 [1,912 kB]\n",
      "Get:33 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvtx-11-0 11.0.167-1 [51.1 kB]\n",
      "Get:34 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-sanitizer-11-0 11.0.167-1 [7,010 kB]\n",
      "Get:35 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-command-line-tools-11-0 11.0.1-1 [2,456 B]\n",
      "Get:36 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-compute-11-0 11.0.1-1 [3,684 B]\n",
      "Get:37 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-systems-11-0 11.0.1-1 [3,248 B]\n",
      "Get:38 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-11-0 11.0.167-1 [119 MB]\n",
      "Get:39 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvml-dev-11-0 11.0.167-1 [71.9 kB]\n",
      "Get:40 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvvp-11-0 11.0.167-1 [115 MB]\n",
      "Get:41 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-visual-tools-11-0 11.0.1-1 [2,912 B]\n",
      "Get:42 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-tools-11-0 11.0.1-1 [2,360 B]\n",
      "Get:43 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-samples-11-0 11.0.167-1 [68.1 MB]\n",
      "Get:44 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-documentation-11-0 11.0.182-1 [63.1 MB]\n",
      "Get:45 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-toolkit-11-0 11.0.1-1 [2,708 B]\n",
      "Get:46 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-demo-suite-11-0 11.0.167-1 [3,948 kB]\n",
      "Get:47 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-11-0 11.0.1-1 [2,434 B]\n",
      "Get:48 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda 11.0.1-1 [2,380 B]\n",
      "Fetched 1,506 MB in 28s (53.5 MB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 48.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package cuda-cudart-11-0.\n",
      "(Reading database ... 144467 files and directories currently installed.)\n",
      "Preparing to unpack .../00-cuda-cudart-11-0_11.0.171-1_amd64.deb ...\n",
      "Unpacking cuda-cudart-11-0 (11.0.171-1) ...\n",
      "Selecting previously unselected package cuda-nvrtc-11-0.\n",
      "Preparing to unpack .../01-cuda-nvrtc-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-nvrtc-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package libcublas-11-0.\n",
      "Preparing to unpack .../02-libcublas-11-0_11.0.0.191-1_amd64.deb ...\n",
      "Unpacking libcublas-11-0 (11.0.0.191-1) ...\n",
      "Selecting previously unselected package libcufft-11-0.\n",
      "Preparing to unpack .../03-libcufft-11-0_10.1.3.191-1_amd64.deb ...\n",
      "Unpacking libcufft-11-0 (10.1.3.191-1) ...\n",
      "Selecting previously unselected package libcurand-11-0.\n",
      "Preparing to unpack .../04-libcurand-11-0_10.2.0.191-1_amd64.deb ...\n",
      "Unpacking libcurand-11-0 (10.2.0.191-1) ...\n",
      "Selecting previously unselected package libcusolver-11-0.\n",
      "Preparing to unpack .../05-libcusolver-11-0_10.4.0.191-1_amd64.deb ...\n",
      "Unpacking libcusolver-11-0 (10.4.0.191-1) ...\n",
      "Selecting previously unselected package libcusparse-11-0.\n",
      "Preparing to unpack .../06-libcusparse-11-0_11.0.0.191-1_amd64.deb ...\n",
      "Unpacking libcusparse-11-0 (11.0.0.191-1) ...\n",
      "Selecting previously unselected package libnpp-11-0.\n",
      "Preparing to unpack .../07-libnpp-11-0_11.0.0.191-1_amd64.deb ...\n",
      "Unpacking libnpp-11-0 (11.0.0.191-1) ...\n",
      "Selecting previously unselected package libnvjpeg-11-0.\n",
      "Preparing to unpack .../08-libnvjpeg-11-0_11.0.0.191-1_amd64.deb ...\n",
      "Unpacking libnvjpeg-11-0 (11.0.0.191-1) ...\n",
      "Selecting previously unselected package cuda-libraries-11-0.\n",
      "Preparing to unpack .../09-cuda-libraries-11-0_11.0.1-1_amd64.deb ...\n",
      "Unpacking cuda-libraries-11-0 (11.0.1-1) ...\n",
      "Selecting previously unselected package cuda-runtime-11-0.\n",
      "Preparing to unpack .../10-cuda-runtime-11-0_11.0.1-1_amd64.deb ...\n",
      "Unpacking cuda-runtime-11-0 (11.0.1-1) ...\n",
      "Selecting previously unselected package cuda-cuobjdump-11-0.\n",
      "Preparing to unpack .../11-cuda-cuobjdump-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-cuobjdump-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-driver-dev-11-0.\n",
      "Preparing to unpack .../12-cuda-driver-dev-11-0_11.0.171-1_amd64.deb ...\n",
      "Unpacking cuda-driver-dev-11-0 (11.0.171-1) ...\n",
      "Selecting previously unselected package cuda-cudart-dev-11-0.\n",
      "Preparing to unpack .../13-cuda-cudart-dev-11-0_11.0.171-1_amd64.deb ...\n",
      "Unpacking cuda-cudart-dev-11-0 (11.0.171-1) ...\n",
      "Selecting previously unselected package cuda-nvcc-11-0.\n",
      "Preparing to unpack .../14-cuda-nvcc-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-nvcc-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-nvprune-11-0.\n",
      "Preparing to unpack .../15-cuda-nvprune-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-nvprune-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-compiler-11-0.\n",
      "Preparing to unpack .../16-cuda-compiler-11-0_11.0.1-1_amd64.deb ...\n",
      "Unpacking cuda-compiler-11-0 (11.0.1-1) ...\n",
      "Selecting previously unselected package cuda-nvrtc-dev-11-0.\n",
      "Preparing to unpack .../17-cuda-nvrtc-dev-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-nvrtc-dev-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package libcublas-dev-11-0.\n",
      "Preparing to unpack .../18-libcublas-dev-11-0_11.0.0.191-1_amd64.deb ...\n",
      "Unpacking libcublas-dev-11-0 (11.0.0.191-1) ...\n",
      "Selecting previously unselected package libcufft-dev-11-0.\n",
      "Preparing to unpack .../19-libcufft-dev-11-0_10.1.3.191-1_amd64.deb ...\n",
      "Unpacking libcufft-dev-11-0 (10.1.3.191-1) ...\n",
      "Selecting previously unselected package libcurand-dev-11-0.\n",
      "Preparing to unpack .../20-libcurand-dev-11-0_10.2.0.191-1_amd64.deb ...\n",
      "Unpacking libcurand-dev-11-0 (10.2.0.191-1) ...\n",
      "Selecting previously unselected package libcusolver-dev-11-0.\n",
      "Preparing to unpack .../21-libcusolver-dev-11-0_10.4.0.191-1_amd64.deb ...\n",
      "Unpacking libcusolver-dev-11-0 (10.4.0.191-1) ...\n",
      "Selecting previously unselected package libcusparse-dev-11-0.\n",
      "Preparing to unpack .../22-libcusparse-dev-11-0_11.0.0.191-1_amd64.deb ...\n",
      "Unpacking libcusparse-dev-11-0 (11.0.0.191-1) ...\n",
      "Selecting previously unselected package libnpp-dev-11-0.\n",
      "Preparing to unpack .../23-libnpp-dev-11-0_11.0.0.191-1_amd64.deb ...\n",
      "Unpacking libnpp-dev-11-0 (11.0.0.191-1) ...\n",
      "Selecting previously unselected package libnvjpeg-dev-11-0.\n",
      "Preparing to unpack .../24-libnvjpeg-dev-11-0_11.0.0.191-1_amd64.deb ...\n",
      "Unpacking libnvjpeg-dev-11-0 (11.0.0.191-1) ...\n",
      "Selecting previously unselected package cuda-libraries-dev-11-0.\n",
      "Preparing to unpack .../25-cuda-libraries-dev-11-0_11.0.1-1_amd64.deb ...\n",
      "Unpacking cuda-libraries-dev-11-0 (11.0.1-1) ...\n",
      "Selecting previously unselected package cuda-cupti-11-0.\n",
      "Preparing to unpack .../26-cuda-cupti-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-cupti-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-cupti-dev-11-0.\n",
      "Preparing to unpack .../27-cuda-cupti-dev-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-cupti-dev-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-nvdisasm-11-0.\n",
      "Preparing to unpack .../28-cuda-nvdisasm-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-nvdisasm-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-gdb-11-0.\n",
      "Preparing to unpack .../29-cuda-gdb-11-0_11.0.172-1_amd64.deb ...\n",
      "Unpacking cuda-gdb-11-0 (11.0.172-1) ...\n",
      "Selecting previously unselected package cuda-memcheck-11-0.\n",
      "Preparing to unpack .../30-cuda-memcheck-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-memcheck-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-nvprof-11-0.\n",
      "Preparing to unpack .../31-cuda-nvprof-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-nvprof-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-nvtx-11-0.\n",
      "Preparing to unpack .../32-cuda-nvtx-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-nvtx-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-sanitizer-11-0.\n",
      "Preparing to unpack .../33-cuda-sanitizer-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-sanitizer-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-command-line-tools-11-0.\n",
      "Preparing to unpack .../34-cuda-command-line-tools-11-0_11.0.1-1_amd64.deb ...\n",
      "Unpacking cuda-command-line-tools-11-0 (11.0.1-1) ...\n",
      "Selecting previously unselected package cuda-nsight-compute-11-0.\n",
      "Preparing to unpack .../35-cuda-nsight-compute-11-0_11.0.1-1_amd64.deb ...\n",
      "Unpacking cuda-nsight-compute-11-0 (11.0.1-1) ...\n",
      "Selecting previously unselected package cuda-nsight-systems-11-0.\n",
      "Preparing to unpack .../36-cuda-nsight-systems-11-0_11.0.1-1_amd64.deb ...\n",
      "Unpacking cuda-nsight-systems-11-0 (11.0.1-1) ...\n",
      "Selecting previously unselected package cuda-nsight-11-0.\n",
      "Preparing to unpack .../37-cuda-nsight-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-nsight-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-nvml-dev-11-0.\n",
      "Preparing to unpack .../38-cuda-nvml-dev-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-nvml-dev-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-nvvp-11-0.\n",
      "Preparing to unpack .../39-cuda-nvvp-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-nvvp-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-visual-tools-11-0.\n",
      "Preparing to unpack .../40-cuda-visual-tools-11-0_11.0.1-1_amd64.deb ...\n",
      "Unpacking cuda-visual-tools-11-0 (11.0.1-1) ...\n",
      "Selecting previously unselected package cuda-tools-11-0.\n",
      "Preparing to unpack .../41-cuda-tools-11-0_11.0.1-1_amd64.deb ...\n",
      "Unpacking cuda-tools-11-0 (11.0.1-1) ...\n",
      "Selecting previously unselected package cuda-samples-11-0.\n",
      "Preparing to unpack .../42-cuda-samples-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-samples-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-documentation-11-0.\n",
      "Preparing to unpack .../43-cuda-documentation-11-0_11.0.182-1_amd64.deb ...\n",
      "Unpacking cuda-documentation-11-0 (11.0.182-1) ...\n",
      "Selecting previously unselected package cuda-toolkit-11-0.\n",
      "Preparing to unpack .../44-cuda-toolkit-11-0_11.0.1-1_amd64.deb ...\n",
      "Unpacking cuda-toolkit-11-0 (11.0.1-1) ...\n",
      "Selecting previously unselected package cuda-demo-suite-11-0.\n",
      "Preparing to unpack .../45-cuda-demo-suite-11-0_11.0.167-1_amd64.deb ...\n",
      "Unpacking cuda-demo-suite-11-0 (11.0.167-1) ...\n",
      "Selecting previously unselected package cuda-11-0.\n",
      "Preparing to unpack .../46-cuda-11-0_11.0.1-1_amd64.deb ...\n",
      "Unpacking cuda-11-0 (11.0.1-1) ...\n",
      "Selecting previously unselected package cuda.\n",
      "Preparing to unpack .../47-cuda_11.0.1-1_amd64.deb ...\n",
      "Unpacking cuda (11.0.1-1) ...\n",
      "Setting up cuda-sanitizer-11-0 (11.0.167-1) ...\n",
      "Setting up cuda-nsight-systems-11-0 (11.0.1-1) ...\n",
      "Setting up cuda-memcheck-11-0 (11.0.167-1) ...\n",
      "Setting up cuda-nvprune-11-0 (11.0.167-1) ...\n",
      "Setting up libcufft-11-0 (10.1.3.191-1) ...\n",
      "Setting up cuda-nsight-11-0 (11.0.167-1) ...\n",
      "Setting up libcusparse-11-0 (11.0.0.191-1) ...\n",
      "Setting up libcublas-11-0 (11.0.0.191-1) ...\n",
      "Setting up cuda-nvdisasm-11-0 (11.0.167-1) ...\n",
      "Setting up libcusolver-11-0 (10.4.0.191-1) ...\n",
      "Setting up cuda-nvrtc-11-0 (11.0.167-1) ...\n",
      "Setting up cuda-nvprof-11-0 (11.0.167-1) ...\n",
      "Setting up libcusolver-dev-11-0 (10.4.0.191-1) ...\n",
      "Setting up cuda-nvtx-11-0 (11.0.167-1) ...\n",
      "Setting up libnpp-11-0 (11.0.0.191-1) ...\n",
      "Setting up libcurand-11-0 (10.2.0.191-1) ...\n",
      "Setting up libcublas-dev-11-0 (11.0.0.191-1) ...\n",
      "Setting up cuda-cuobjdump-11-0 (11.0.167-1) ...\n",
      "Setting up libcurand-dev-11-0 (10.2.0.191-1) ...\n",
      "Setting up libnpp-dev-11-0 (11.0.0.191-1) ...\n",
      "Setting up cuda-nvvp-11-0 (11.0.167-1) ...\n",
      "Setting up cuda-nvml-dev-11-0 (11.0.167-1) ...\n",
      "Setting up libnvjpeg-11-0 (11.0.0.191-1) ...\n",
      "Setting up cuda-driver-dev-11-0 (11.0.171-1) ...\n",
      "Setting up cuda-cudart-11-0 (11.0.171-1) ...\n",
      "Setting up cuda-nsight-compute-11-0 (11.0.1-1) ...\n",
      "Setting up libcufft-dev-11-0 (10.1.3.191-1) ...\n",
      "Setting up libcusparse-dev-11-0 (11.0.0.191-1) ...\n",
      "Setting up cuda-gdb-11-0 (11.0.172-1) ...\n",
      "Setting up libnvjpeg-dev-11-0 (11.0.0.191-1) ...\n",
      "Setting up cuda-cudart-dev-11-0 (11.0.171-1) ...\n",
      "Setting up cuda-libraries-11-0 (11.0.1-1) ...\n",
      "Setting up cuda-nvrtc-dev-11-0 (11.0.167-1) ...\n",
      "Setting up cuda-visual-tools-11-0 (11.0.1-1) ...\n",
      "Setting up cuda-libraries-dev-11-0 (11.0.1-1) ...\n",
      "Setting up cuda-nvcc-11-0 (11.0.167-1) ...\n",
      "Setting up cuda-runtime-11-0 (11.0.1-1) ...\n",
      "Setting up cuda-samples-11-0 (11.0.167-1) ...\n",
      "Setting up cuda-demo-suite-11-0 (11.0.167-1) ...\n",
      "Setting up cuda-compiler-11-0 (11.0.1-1) ...\n",
      "Setting up cuda-documentation-11-0 (11.0.182-1) ...\n",
      "Setting up cuda-cupti-11-0 (11.0.167-1) ...\n",
      "Setting up cuda-cupti-dev-11-0 (11.0.167-1) ...\n",
      "Setting up cuda-command-line-tools-11-0 (11.0.1-1) ...\n",
      "Setting up cuda-tools-11-0 (11.0.1-1) ...\n",
      "Setting up cuda-toolkit-11-0 (11.0.1-1) ...\n",
      "Setting up cuda-11-0 (11.0.1-1) ...\n",
      "Setting up cuda (11.0.1-1) ...\n"
     ]
    }
   ],
   "source": [
    "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
    "!sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
    "!wget http://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb\n",
    "!sudo dpkg -i cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb\n",
    "!sudo apt-key add /var/cuda-repo-10-2-local-10.2.89-440.33.01/7fa2af80.pub\n",
    "!sudo apt-get update\n",
    "!sudo apt-get -y install cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFkTjvIsmReg"
   },
   "source": [
    "安装mxnet和gluonnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 111983,
     "status": "ok",
     "timestamp": 1593854556398,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "cVzGZo8lmqJb",
    "outputId": "07fd5f91-ba17-41b7-acbd-a1f29c3ba145"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://dist.mxnet.io/python\n",
      "Collecting mxnet-cu100==1.6.0\n",
      "\u001b[?25l  Downloading https://repo.mxnet.io/dist/python/cu100/mxnet_cu100-1.6.0-py2.py3-none-manylinux1_x86_64.whl (695.0MB)\n",
      "\u001b[K     |████████████████████████████████| 695.0MB 27kB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100==1.6.0) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100==1.6.0) (1.18.5)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100==1.6.0) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100==1.6.0) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100==1.6.0) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100==1.6.0) (2.9)\n",
      "Installing collected packages: graphviz, mxnet-cu100\n",
      "  Found existing installation: graphviz 0.10.1\n",
      "    Uninstalling graphviz-0.10.1:\n",
      "      Successfully uninstalled graphviz-0.10.1\n",
      "Successfully installed graphviz-0.8.4 mxnet-cu100-1.6.0\n",
      "Collecting gluonnlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/27/07b57d22496ed6c98b247e578712122402487f5c265ec70a747900f97060/gluonnlp-0.9.1.tar.gz (252kB)\n",
      "\u001b[K     |████████████████████████████████| 256kB 2.7MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: cython in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (0.29.20)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (1.12.0)\n",
      "Building wheels for collected packages: gluonnlp\n",
      "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gluonnlp: filename=gluonnlp-0.9.1-cp36-cp36m-linux_x86_64.whl size=470051 sha256=8e14d2b7dcca01e372a1fa785b7c270c45c71c0a9a00775320664d73629f8dda\n",
      "  Stored in directory: /root/.cache/pip/wheels/af/60/16/1f8a40e68b85bd9bd7960e91830bca5e40cd113f3220b7e231\n",
      "Successfully built gluonnlp\n",
      "Installing collected packages: gluonnlp\n",
      "Successfully installed gluonnlp-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade mxnet-cu100==1.6.0 -f https://dist.mxnet.io/python\n",
    "!pip install --upgrade gluonnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2704,
     "status": "ok",
     "timestamp": 1593855521992,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "m8KfdPekuByK",
    "outputId": "6be01e31-35b9-4613-ddeb-e03fabcf6117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5776,
     "status": "ok",
     "timestamp": 1593855531972,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "u-bb5cxQuZKv",
    "outputId": "c6de96b1-23bf-42e7-ed6b-afed34cb987e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention-nlp.png\tdev.tsv\n",
      "bert\t\t\telmo_sentence_representation.ipynb\n",
      "bert-embed.png\t\tindex.rst\n",
      "bert.ipynb\t\tlabeledTrainData.tsv\n",
      "bert.png\t\tself_attentive_sentence_embedding.ipynb\n",
      "bert-sentence-pair.png\ttestData.tsv\n",
      "Bi-LSTM-Rep.png\t\tUntitled0.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/content/gdrive/My Drive/finetune\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lXCshe-nm3-i"
   },
   "source": [
    "导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2751,
     "status": "ok",
     "timestamp": 1593855534637,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "D3_0Cp0lm6NI"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import io\n",
    "import random\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "from gluonnlp.calibration import BertLayerCollector\n",
    "# this notebook assumes that all required scripts are already\n",
    "# downloaded from the corresponding tutorial webpage on http://gluon-nlp.mxnet.io\n",
    "\n",
    "from bert import data\n",
    "\n",
    "nlp.utils.check_version('0.8.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "msci15SxnA4R"
   },
   "source": [
    "设置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1135,
     "status": "ok",
     "timestamp": 1593855538532,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "5305zYgdnDZs"
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)\n",
    "# change `ctx` to `mx.cpu()` if no GPU is available.\n",
    "ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4x9DI9qBnG57"
   },
   "source": [
    "导入BERT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6241,
     "status": "ok",
     "timestamp": 1593855546439,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "X9wnlCGAnIs_",
    "outputId": "b3a997c5-7be8-493f-a9ee-de1afaf72b68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTModel(\n",
      "  (encoder): BERTEncoder(\n",
      "    (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "    (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (1): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (2): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (3): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (4): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (5): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (6): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (7): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (8): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (9): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (10): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (11): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): DotProductSelfAttentionCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_embed): HybridSequential(\n",
      "    (0): Embedding(30522 -> 768, float32)\n",
      "  )\n",
      "  (token_type_embed): HybridSequential(\n",
      "    (0): Embedding(2 -> 768, float32)\n",
      "  )\n",
      "  (pooler): Dense(768 -> 768, Activation(tanh))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "bert_base, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
    "                        dataset_name='book_corpus_wiki_en_uncased',\n",
    "                        pretrained=True, ctx=ctx, use_pooler=True,\n",
    "                        use_decoder=False, use_classifier=False)\n",
    "print(bert_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1o4YZWWsnL3R"
   },
   "source": [
    "将模型用于分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1238,
     "status": "ok",
     "timestamp": 1593855550808,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "d19vGBRfnV0F"
   },
   "outputs": [],
   "source": [
    "bert_classifier = nlp.model.BERTClassifier(bert_base, num_classes=2, dropout=0.1)\n",
    "# only need to initialize the classifier layer.\n",
    "bert_classifier.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "bert_classifier.hybridize(static_alloc=True)\n",
    "\n",
    "# softmax cross entropy loss for classification\n",
    "loss_function = mx.gluon.loss.SoftmaxCELoss()\n",
    "loss_function.hybridize(static_alloc=True)\n",
    "\n",
    "metric = mx.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWBturaVnXBl"
   },
   "source": [
    "导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1319,
     "status": "ok",
     "timestamp": 1593855554985,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "Dki8ISFrn2lc",
    "outputId": "ea981b0a-b7d6-4d37-a0f0-4deda7d4f174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\tsentiment\treview\n",
      "\n",
      "\"5814_8\"\t1\t\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"\n",
      "\n",
      "\"2381_9\"\t1\t\"\\\"The Classic War of the Worlds\\\" by Timothy Hines is a very entertaining film that obviously goes to great effort and lengths to faithfully recreate H. G. Wells' classic book. Mr. Hines succeeds in doing so. I, and those who watched his film with me, appreciated the fact that it was not the standard, predictable Hollywood fare that comes out every year, e.g. the Spielberg version with Tom Cruise that had only the slightest resemblance to the book. Obviously, everyone looks for different things in a movie. Those who envision themselves as amateur \\\"critics\\\" look only to criticize everything they can. Others rate a movie on more important bases,like being entertained, which is why most people never agree with the \\\"critics\\\". We enjoyed the effort Mr. Hines put into being faithful to H.G. Wells' classic novel, and we found it to be very entertaining. This made it easy to overlook what the \\\"critics\\\" perceive to be its shortcomings.\"\n",
      "\n",
      "\"7759_3\"\t0\t\"The film starts with a manager (Nicholas Bell) giving welcome investors (Robert Carradine) to Primal Park . A secret project mutating a primal animal using fossilized DNA, like ¨Jurassik Park¨, and some scientists resurrect one of nature's most fearsome predators, the Sabretooth tiger or Smilodon . Scientific ambition turns deadly, however, and when the high voltage fence is opened the creature escape and begins savagely stalking its prey - the human visitors , tourists and scientific.Meanwhile some youngsters enter in the restricted area of the security center and are attacked by a pack of large pre-historical animals which are deadlier and bigger . In addition , a security agent (Stacy Haiduk) and her mate (Brian Wimmer) fight hardly against the carnivorous Smilodons. The Sabretooths, themselves , of course, are the real star stars and they are astounding terrifyingly though not convincing. The giant animals savagely are stalking its prey and the group run afoul and fight against one nature's most fearsome predators. Furthermore a third Sabretooth more dangerous and slow stalks its victims.<br /><br />The movie delivers the goods with lots of blood and gore as beheading, hair-raising chills,full of scares when the Sabretooths appear with mediocre special effects.The story provides exciting and stirring entertainment but it results to be quite boring .The giant animals are majority made by computer generator and seem totally lousy .Middling performances though the players reacting appropriately to becoming food.Actors give vigorously physical performances dodging the beasts ,running,bound and leaps or dangling over walls . And it packs a ridiculous final deadly scene. No for small kids by realistic,gory and violent attack scenes . Other films about Sabretooths or Smilodon are the following : ¨Sabretooth(2002)¨by James R Hickox with Vanessa Angel, David Keith and John Rhys Davies and the much better ¨10.000 BC(2006)¨ by Roland Emmerich with with Steven Strait, Cliff Curtis and Camilla Belle. This motion picture filled with bloody moments is badly directed by George Miller and with no originality because takes too many elements from previous films. Miller is an Australian director usually working for television (Tidal wave, Journey to the center of the earth, and many others) and occasionally for cinema ( The man from Snowy river, Zeus and Roxanne,Robinson Crusoe ). Rating : Below average, bottom of barrel.\"\n",
      "\n",
      "\"3630_4\"\t0\t\"It must be assumed that those who praised this film (\\\"the greatest filmed opera ever,\\\" didn't I read somewhere?) either don't care for opera, don't care for Wagner, or don't care about anything except their desire to appear Cultured. Either as a representation of Wagner's swan-song, or as a movie, this strikes me as an unmitigated disaster, with a leaden reading of the score matched to a tricksy, lugubrious realisation of the text.<br /><br />It's questionable that people with ideas as to what an opera (or, for that matter, a play, especially one by Shakespeare) is \\\"about\\\" should be allowed anywhere near a theatre or film studio; Syberberg, very fashionably, but without the smallest justification from Wagner's text, decided that Parsifal is \\\"about\\\" bisexual integration, so that the title character, in the latter stages, transmutes into a kind of beatnik babe, though one who continues to sing high tenor -- few if any of the actors in the film are the singers, and we get a double dose of Armin Jordan, the conductor, who is seen as the face (but not heard as the voice) of Amfortas, and also appears monstrously in double exposure as a kind of Batonzilla or Conductor Who Ate Monsalvat during the playing of the Good Friday music -- in which, by the way, the transcendant loveliness of nature is represented by a scattering of shopworn and flaccid crocuses stuck in ill-laid turf, an expedient which baffles me. In the theatre we sometimes have to piece out such imperfections with our thoughts, but I can't think why Syberberg couldn't splice in, for Parsifal and Gurnemanz, mountain pasture as lush as was provided for Julie Andrews in Sound of Music...<br /><br />The sound is hard to endure, the high voices and the trumpets in particular possessing an aural glare that adds another sort of fatigue to our impatience with the uninspired conducting and paralytic unfolding of the ritual. Someone in another review mentioned the 1951 Bayreuth recording, and Knappertsbusch, though his tempi are often very slow, had what Jordan altogether lacks, a sense of pulse, a feeling for the ebb and flow of the music -- and, after half a century, the orchestral sound in that set, in modern pressings, is still superior to this film.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsv_file = io.open('labeledTrainData.tsv', encoding='utf-8')\n",
    "for i in range(5):\n",
    "    print(tsv_file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BAhkELhIoDiP"
   },
   "source": [
    "数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1052,
     "status": "ok",
     "timestamp": 1593855556624,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "3SwLEpg_oFgH",
    "outputId": "01dc417c-eb7d-4027-e37f-ba797d0de028"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"There is a uk edition to this show which is rather less extravagant than the US version. The person concerned will get a new kitchen or perhaps bedroom and bathroom and is wonderfully grateful for what they have got. The US version of this show is everything that reality TV shouldn't be. Instead of making a few improvements to a house which the occupants could not afford or do themselves the entire house gets rebuilt. I do not know if this show is trying to show what a lousy welfare system exists in the US or if you beg hard enough you will receive. The rather vulgar product placement that takes place, particularly by Sears, is also uncalled for. Rsther than turning one family in a deprived area into potential millionaires, it would be far better to help the community as a whole where instead of spending the hundreds of thousands of dollars on one home, build something for the whole community ..... perhaps a place where diy and power tools can be borrowed and returned along with building materials so that everyone can benefit should they want to. Giving it all to one person can cause enormous resentment among the rest of the local community who still live in the same run down houses.\"\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Skip the first line, which is the schema\n",
    "num_discard_samples = 1\n",
    "# Split fields by tabs\n",
    "field_separator = nlp.data.Splitter('\\t')\n",
    "sample_splitter = nlp.data.Splitter('\\n')\n",
    "# Fields to select from the file\n",
    "field_indices = [2,1]\n",
    "data_train_raw = nlp.data.TSVDataset(filename='labeledTrainData.tsv',\n",
    "                  sample_splitter=sample_splitter,\n",
    "                  field_separator=field_separator,\n",
    "                  num_discard_samples=num_discard_samples,\n",
    "                  field_indices=field_indices)\n",
    "sample_id = 100\n",
    "# Sentence\n",
    "print(data_train_raw[sample_id][0])\n",
    "# label\n",
    "print(data_train_raw[sample_id][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1110,
     "status": "ok",
     "timestamp": 1593855561129,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "Hjc6t8QX4Ktf",
    "outputId": "dcac3966-cc51-4e56-f30c-074e240f2e86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "token ids = \n",
      "[    2  1000  2045  2003  1037  2866  3179  2000  2023  2265  2029  2003\n",
      "  2738  2625 27856  2084  1996  2149  2544  1012  1996  2711  4986  2097\n",
      "  2131  1037  2047  3829  2030  3383  5010  1998  5723  1998  2003  6919\n",
      "  2135  8794  2005  2054  2027  2031  2288  1012  1996  2149  2544  1997\n",
      "  2023  2265  2003  2673  2008  4507  2694  5807  1005  1056  2022  1012\n",
      "  2612  1997  2437  1037  2261  8377  2000  1037  2160  2029  1996 18837\n",
      "  2071  2025  8984  2030  2079  3209  1996  2972  2160  4152  7183  1012\n",
      "  1045  2079  2025  2113  2065  2023  2265  2003  2667  2000  2265  2054\n",
      "  1037 10223  6508  7574  2291  6526  1999  1996  2149  2030  2065  2017\n",
      " 11693  2524  2438  2017  2097  4374  1012  1996  2738 29364  4031 11073\n",
      "  2008  3138  2173  1010  3391  2011 18493     3]\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "valid length = \n",
      "128\n",
      "label = \n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Use the vocabulary from pre-trained model for tokenization\n",
    "bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "\n",
    "# The maximum length of an input sequence\n",
    "max_len = 128\n",
    "\n",
    "# The labels for the two classes [(0 = not similar) or  (1 = similar)]\n",
    "all_labels = [\"0\", \"1\"]\n",
    "\n",
    "# whether to transform the data as sentence pairs.\n",
    "# for single sentence classification, set pair=False\n",
    "# for regression task, set class_labels=None\n",
    "# for inference without label available, set has_label=False\n",
    "pair = False\n",
    "transform = data.transform.BERTDatasetTransform(bert_tokenizer, max_len,\n",
    "                        class_labels=all_labels,\n",
    "                        has_label=True,\n",
    "                        pad=True,\n",
    "                        pair=pair)\n",
    "data_train = data_train_raw.transform(transform)\n",
    "\n",
    "print('vocabulary used for tokenization = \\n%s'%vocabulary)\n",
    "print('%s token id = %s'%(vocabulary.padding_token, vocabulary[vocabulary.padding_token]))\n",
    "print('%s token id = %s'%(vocabulary.cls_token, vocabulary[vocabulary.cls_token]))\n",
    "print('%s token id = %s'%(vocabulary.sep_token, vocabulary[vocabulary.sep_token]))\n",
    "print('token ids = \\n%s'%data_train[sample_id][0])\n",
    "print('segment ids = \\n%s'%data_train[sample_id][1])\n",
    "print('valid length = \\n%s'%data_train[sample_id][2])\n",
    "print('label = \\n%s'%data_train[sample_id][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-i-fq1b4vRK"
   },
   "source": [
    "微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1024945,
     "status": "ok",
     "timestamp": 1593856722431,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "mlWddefZ4gvh",
    "outputId": "edbec072-ce03-4468-a6af-7a118053ee88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 100/785] loss=0.6187, lr=0.0000050, acc=0.679\n",
      "[Epoch 0 Batch 200/785] loss=0.4251, lr=0.0000050, acc=0.746\n",
      "[Epoch 0 Batch 300/785] loss=0.3883, lr=0.0000050, acc=0.775\n",
      "[Epoch 0 Batch 400/785] loss=0.3319, lr=0.0000050, acc=0.796\n",
      "[Epoch 0 Batch 500/785] loss=0.3408, lr=0.0000050, acc=0.807\n",
      "[Epoch 0 Batch 600/785] loss=0.3170, lr=0.0000050, acc=0.816\n",
      "[Epoch 0 Batch 700/785] loss=0.3299, lr=0.0000050, acc=0.822\n",
      "[Epoch 1 Batch 100/785] loss=0.2771, lr=0.0000050, acc=0.882\n",
      "[Epoch 1 Batch 200/785] loss=0.2776, lr=0.0000050, acc=0.882\n",
      "[Epoch 1 Batch 300/785] loss=0.2943, lr=0.0000050, acc=0.879\n",
      "[Epoch 1 Batch 400/785] loss=0.2915, lr=0.0000050, acc=0.879\n",
      "[Epoch 1 Batch 500/785] loss=0.2677, lr=0.0000050, acc=0.881\n",
      "[Epoch 1 Batch 600/785] loss=0.2806, lr=0.0000050, acc=0.882\n",
      "[Epoch 1 Batch 700/785] loss=0.2776, lr=0.0000050, acc=0.882\n",
      "[Epoch 2 Batch 100/785] loss=0.2347, lr=0.0000050, acc=0.904\n",
      "[Epoch 2 Batch 200/785] loss=0.2321, lr=0.0000050, acc=0.907\n",
      "[Epoch 2 Batch 300/785] loss=0.2167, lr=0.0000050, acc=0.908\n",
      "[Epoch 2 Batch 400/785] loss=0.2136, lr=0.0000050, acc=0.910\n",
      "[Epoch 2 Batch 500/785] loss=0.2501, lr=0.0000050, acc=0.908\n",
      "[Epoch 2 Batch 600/785] loss=0.2297, lr=0.0000050, acc=0.908\n",
      "[Epoch 2 Batch 700/785] loss=0.2291, lr=0.0000050, acc=0.908\n"
     ]
    }
   ],
   "source": [
    "# The hyperparameters\n",
    "batch_size = 32\n",
    "lr = 5e-6\n",
    "\n",
    "# The FixedBucketSampler and the DataLoader for making the mini-batches\n",
    "train_sampler = nlp.data.FixedBucketSampler(lengths=[int(item[2]) for item in data_train],\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True)\n",
    "bert_dataloader = mx.gluon.data.DataLoader(data_train, batch_sampler=train_sampler)\n",
    "\n",
    "trainer = mx.gluon.Trainer(bert_classifier.collect_params(), 'adam',\n",
    "                           {'learning_rate': lr, 'epsilon': 1e-9})\n",
    "\n",
    "# Collect all differentiable parameters\n",
    "# `grad_req == 'null'` indicates no gradients are calculated (e.g. constant parameters)\n",
    "# The gradients for these params are clipped later\n",
    "params = [p for p in bert_classifier.collect_params().values() if p.grad_req != 'null']\n",
    "grad_clip = 1\n",
    "\n",
    "# Training the model with only three epochs\n",
    "log_interval = 100\n",
    "num_epochs = 3\n",
    "for epoch_id in range(num_epochs):\n",
    "    metric.reset()\n",
    "    step_loss = 0\n",
    "    for batch_id, (token_ids, segment_ids, valid_length, label) in enumerate(bert_dataloader):\n",
    "        with mx.autograd.record():\n",
    "\n",
    "        # Load the data to the GPU\n",
    "        token_ids = token_ids.as_in_context(ctx)\n",
    "        valid_length = valid_length.as_in_context(ctx)\n",
    "        segment_ids = segment_ids.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "\n",
    "        # Forward computation\n",
    "        out = bert_classifier(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "        ls = loss_function(out, label).mean()\n",
    "\n",
    "        # And backwards computation\n",
    "        ls.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        trainer.allreduce_grads()\n",
    "        nlp.utils.clip_grad_global_norm(params, 1)\n",
    "        trainer.update(1)\n",
    "\n",
    "        step_loss += ls.asscalar()\n",
    "        metric.update([label], [out])\n",
    "\n",
    "        # Printing vital information\n",
    "        if (batch_id + 1) % (log_interval) == 0:\n",
    "            print('[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f}'\n",
    "                .format(epoch_id, batch_id + 1, len(bert_dataloader),\n",
    "                step_loss / log_interval,\n",
    "                trainer.learning_rate, metric.get()[1]))\n",
    "            step_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1313,
     "status": "error",
     "timestamp": 1593870865103,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "mrvtvF_AGNZr",
    "outputId": "2dea0565-4057-40b9-d007-1ad9b556b186"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-e84e216fb0da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbert_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gluonnlp/utils/parameter.py\u001b[0m in \u001b[0;36msave_parameters\u001b[0;34m(model, filename)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mPath\u001b[0m \u001b[0mto\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0m_s3_compatible_save_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gluonnlp/utils/parameter.py\u001b[0m in \u001b[0;36m_s3_compatible_save_load\u001b[0;34m(is_save, save_load_method, filename, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_s3_compatible_save_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_load_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;34m\"\"\"Dispatch function for save load with s3.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS3_PREFIX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;31m# create temp dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_TempFilePath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtemp_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'BERTClassifier' is not iterable"
     ]
    }
   ],
   "source": [
    "nlp.utils.save_parameters(bert_classifier,bert_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szCW6tuLWRWx"
   },
   "source": [
    "测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1808,
     "status": "ok",
     "timestamp": 1593867152544,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "x3M7ZONnYF3m",
    "outputId": "c6c9429c-dacc-4353-8164-2d25a3720647"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"Naturally in a film who's main themes are of mortality, nostalgia, and loss of innocence it is perhaps not surprising that it is rated more highly by older viewers than younger ones. However there is a craftsmanship and completeness to the film which anyone can enjoy. The pace is steady and constant, the characters full and engaging, the relationships and interactions natural showing that you do not need floods of tears to show emotion, screams to show fear, shouting to show dispute or violence to show anger. Naturally Joyce's short story lends the film a ready made structure as perfect as a polished diamond, but the small changes Huston makes such as the inclusion of the poem fit in neatly. It is truly a masterpiece of tact, subtlety and overwhelming beauty.\"\"\"\t0\n",
      "\n",
      "\"\"\"Afraid of the Dark left me with the impression that several different screenplays were written, all too short for a feature length film, then spliced together clumsily into this Frankenstein's monster.<br /><br />At his best, the protagonist, Lucas, is creepy. As hard as it is to draw a bead on the secondary characters, they're far more sympathetic.<br /><br />Afraid of the Dark could have achieved mediocrity had it taken just one approach and seen it through -- and had it made Lucas simply psychotic and confused instead of ghoulish and off-putting. I wanted to see him packed off into an asylum so the rest of the characters could have a normal life.\"\"\"\t0\n",
      "\n",
      "token ids = \n",
      "[    2  1000  1000  1000  8100  1999  1037  2143  2040  1005  1055  2364\n",
      "  6991  2024  1997 13356  1010 26968  1010  1998  3279  1997 12660  2009\n",
      "  2003  3383  2025 11341  2008  2009  2003  6758  2062  3811  2011  3080\n",
      "  7193  2084  3920  3924  1012  2174  2045  2003  1037 26286  9650  1998\n",
      "  3143  2791  2000  1996  2143  2029  3087  2064  5959  1012  1996  6393\n",
      "  2003  6706  1998  5377  1010  1996  3494  2440  1998 11973  1010  1996\n",
      "  6550  1998 10266  3019  4760  2008  2017  2079  2025  2342 14295  1997\n",
      "  4000  2000  2265  7603  1010 11652  2000  2265  3571  1010 11273  2000\n",
      "  2265  7593  2030  4808  2000  2265  4963  1012  8100 11830  1005  1055\n",
      "  2460  2466 18496  2015  1996  2143  1037  3201  2081  3252  2004  3819\n",
      "  2004  1037 12853  6323  1010  2021  1996     3]\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "valid length = \n",
      "128\n"
     ]
    }
   ],
   "source": [
    "type(data_train_raw[sample_id][0])\n",
    "tsv_try = io.open('try0.tsv', encoding='utf-8')\n",
    "print(tsv_try.readline())\n",
    "print(tsv_try.readline())\n",
    "data_try_row = nlp.data.TSVDataset(filename='try0.tsv',\n",
    "                sample_splitter=sample_splitter,\n",
    "                field_separator=field_separator,\n",
    "                )\n",
    "data_try=data_try_row.transform(transform)\n",
    "print('token ids = \\n%s'%data_try[0][0])\n",
    "print('segment ids = \\n%s'%data_try[0][1])\n",
    "print('valid length = \\n%s'%data_try[0][2])\n",
    "\n",
    "try_sampler = nlp.data.FixedBucketSampler(lengths=[int(item[2]) for item in data_try],\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=False)\n",
    "try_dataloader = mx.gluon.data.DataLoader(data_try, batch_sampler=try_sampler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1742,
     "status": "ok",
     "timestamp": 1593867159074,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "JTB95bzQ0Qsr",
    "outputId": "b8d24835-8fbd-40ce-8ae4-5a50f9efc81f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[-2.1882935  2.5862806]\n",
      " [ 2.4543023 -2.3242462]]\n",
      "<NDArray 2x2 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "ctx=mx.gpu(0)\n",
    "for batch_id, (token_ids, segment_ids, valid_length, label) in enumerate(try_dataloader):\n",
    "\n",
    "        # Load the data to the GPU\n",
    "        token_ids = token_ids.as_in_context(ctx)\n",
    "        valid_length = valid_length.as_in_context(ctx)\n",
    "        segment_ids = segment_ids.as_in_context(ctx)\n",
    "\n",
    "        # Forward computation\n",
    "        out = bert_classifier(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "        \n",
    "        print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1114,
     "status": "ok",
     "timestamp": 1593869775290,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "_OqBEyCG6YaM",
    "outputId": "831129ba-901b-401f-8b14-3b0ff0fc64ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence polarity\n",
      "  0      positive\n",
      "  1      negative\n"
     ]
    }
   ],
   "source": [
    "#type(out)\n",
    "#out.shape\n",
    "#mm=mx.ndarray.max(out,2)\n",
    "print(\"sentence\",\"polarity\")\n",
    "output=out.argmax(axis=1)\n",
    "for item in range(len(output)):\n",
    "  if(mm[item]==1):\n",
    "    print(\" \",item,\"     positive\")\n",
    "  else:\n",
    "    print(\" \",item,\"     negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p7HiPENbtqk8"
   },
   "source": [
    "测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1100,
     "status": "error",
     "timestamp": 1593865432202,
     "user": {
      "displayName": "李若琦",
      "photoUrl": "",
      "userId": "09134208964329251407"
     },
     "user_tz": -480
    },
    "id": "LyO8Y2pDtqPV",
    "outputId": "1e4e01b3-b8cd-43ce-a54b-c3d76c44d083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\\\"One True Thing\\\" is a very quiet film, that opened in the fall of 1998 to glowing reviews but mild box-office. It tells the crippled story of Ellen (Renee Zellweger), a workaholic who is forced to move back home to take care of her terminally ill mother (Meryl Streep), so that her aloof father (William Hurt) can run his academic department. These terms are only general. The strength of \\\"One True Thing\\\" lies in the way the actors elevate their characters above Hollywood cliché territory.<br /><br />Streep is Kate, the perfect homemaker whose ability to light up a room with her charm is evident in her opening scenes at a costume party celebrating Hurt's birthday. But Ellen has never been close to her mother, and since she graduated from Harvard University, has a certain destain about her- Ellen almost thinks her mother is a simplistic air-head. While on the other hand, she admires her father- who shares a special passion: Writing. Ellen writes for an aggressive New York firm, and is almost heartbroken when her latest piece is torn down by Hurt, who seems to be a very lonely figure.<br /><br />To get to the point, as Kate gets sicker, Ellen's perspectives change and she grows closer to her mother and more distant to her father. Hurt keeps making excuses not to be there when the family needs him most, and Ellen assumes he's having an affair. Meanwhile she's given up her desk at work to spend time doing craft activities with her mother's \\\"cult\\\" group The Minnies, and also learning that her mother isn't as weak as she first assumed.<br /><br />Without giving too much away, \\\"One True Thing\\\" is a masterpiece in character study. Streep once again turns in a beautiful performance, this time working on a subtle level that starts slow but ends with a brilliant speech on the vows of marriage. Streep earned her eleventh Oscar nomination for this performance. Hurt is also convincing as the father who carries a secret that isn't revealed until the closing moments. But it is Renee Zellweger who steals this movie. Forget \\\"Chicago\\\", \\\"Cold Mountain\\\", \\\"Bridget Jones's Diary\\\" or whatever else you've seen her do and rent this movie. She is remarkable in it. Working within her character's bitter resentment at understanding her parents, Zellweger manages a realistic portrayal of a young woman fighting to keep her lip up while she's screaming inside.\"\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-0408ade17ff6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_test_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'token ids = \\n%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'segment ids = \\n%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid length = \\n%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/gdrive/My Drive/finetune/bert/data/transform.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;31m# map to int if class labels are available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '\"7080_9\"'"
     ]
    }
   ],
   "source": [
    "field_indices=[1]\n",
    "data_test_raw = nlp.data.TSVDataset(filename='testData.tsv',\n",
    "                  sample_splitter=sample_splitter,\n",
    "                  field_separator=field_separator,\n",
    "                  num_discard_samples=num_discard_samples,\n",
    "                  field_indices=field_indices)\n",
    "sample_id = 100\n",
    "# Sentence\n",
    "print(data_test_raw[sample_id][0])\n",
    "\n",
    "\n",
    "data_test = data_test_raw.transform(transform)\n",
    "\n",
    "print('token ids = \\n%s'%data_test[sample_id][0])\n",
    "print('segment ids = \\n%s'%data_test[sample_id][1])\n",
    "print('valid length = \\n%s'%data_test[sample_id][2])\n",
    "\n",
    "\n",
    "test_sampler = nlp.data.FixedBucketSampler(batch_size=batch_size,\n",
    "                      shuffle=True)\n",
    "test_dataloader = mx.gluon.data.DataLoader(data_test, batch_sampler=test_sampler)\n",
    "\n",
    "for batch_id, (token_ids, segment_ids, valid_length, label) in enumerate(test_dataloader):\n",
    "\n",
    "        # Load the data to the GPU\n",
    "        token_ids = token_ids.as_in_context(ctx)\n",
    "        valid_length = valid_length.as_in_context(ctx)\n",
    "        segment_ids = segment_ids.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "\n",
    "        # Forward computation\n",
    "        out = bert_classifier(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "        print(out)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP95ne+8vfZYTFw/rKHj7xS",
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
